{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4222,
     "status": "ok",
     "timestamp": 1687496977831,
     "user": {
      "displayName": "Sadia Iqbal",
      "userId": "13577405437173025394"
     },
     "user_tz": 420
    },
    "id": "uUGEV_C0I6zp",
    "outputId": "37335b1f-6a77-4d5a-af45-0dc7f9869b2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1687496977834,
     "user": {
      "displayName": "Sadia Iqbal",
      "userId": "13577405437173025394"
     },
     "user_tz": 420
    },
    "id": "ltM7KloTP1Mc",
    "outputId": "e0c165d0-fa06-4009-df3b-23fe1339c590"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cf0bab92-1e44-4f68-a8f9-9d716366f04d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@isadia_</td>\n",
       "      <td>05/06/2023</td>\n",
       "      <td>Just had the best day ever!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@isadia_</td>\n",
       "      <td>06/06/2023</td>\n",
       "      <td>Feeling down today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@isadia_</td>\n",
       "      <td>07/06/2023</td>\n",
       "      <td>So excited for the weekend!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@isadia_</td>\n",
       "      <td>08/06/2023</td>\n",
       "      <td>Can't believe how much I accomplished!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@isadia_</td>\n",
       "      <td>09/06/2023</td>\n",
       "      <td>This weather is awful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>@arefu_bot</td>\n",
       "      <td>10/06/2023</td>\n",
       "      <td>\"The sun always rises after the darkest night.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>@arefu_bot</td>\n",
       "      <td>11/06/2023</td>\n",
       "      <td>\"Every day is a fresh start.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>@arefu_bot</td>\n",
       "      <td>11/06/2023</td>\n",
       "      <td>\"Your smile brightens the world.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>@arefu_bot</td>\n",
       "      <td>11/06/2023</td>\n",
       "      <td>\"You have a unique and valuable perspective.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>@arefu_bot</td>\n",
       "      <td>11/06/2023</td>\n",
       "      <td>\"Opportunities are abundant if you seek them.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows Ã— 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf0bab92-1e44-4f68-a8f9-9d716366f04d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-cf0bab92-1e44-4f68-a8f9-9d716366f04d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-cf0bab92-1e44-4f68-a8f9-9d716366f04d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       username        Date                                             text\n",
       "0      @isadia_  05/06/2023                      Just had the best day ever!\n",
       "1      @isadia_  06/06/2023                              Feeling down today.\n",
       "2      @isadia_  07/06/2023                      So excited for the weekend!\n",
       "3      @isadia_  08/06/2023           Can't believe how much I accomplished!\n",
       "4      @isadia_  09/06/2023                           This weather is awful.\n",
       "..          ...         ...                                              ...\n",
       "100  @arefu_bot  10/06/2023  \"The sun always rises after the darkest night.\"\n",
       "101  @arefu_bot  11/06/2023                    \"Every day is a fresh start.\"\n",
       "102  @arefu_bot  11/06/2023                \"Your smile brightens the world.\"\n",
       "103  @arefu_bot  11/06/2023    \"You have a unique and valuable perspective.\"\n",
       "104  @arefu_bot  11/06/2023   \"Opportunities are abundant if you seek them.\"\n",
       "\n",
       "[105 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ä°mport dataset\n",
    "df = pd.read_csv(\"testing_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6876,
     "status": "ok",
     "timestamp": 1687496984665,
     "user": {
      "displayName": "Sadia Iqbal",
      "userId": "13577405437173025394"
     },
     "user_tz": 420
    },
    "id": "gr4eGbGCQqW_",
    "outputId": "23944408-d8f4-4d9c-fe4c-f23fabbc6d25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the username to search: @w_n_w\n"
     ]
    }
   ],
   "source": [
    "# Get user input for the username\n",
    "#username = input(\"Enter the username to search: \")\n",
    "username = input(\"Enter the username to search: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1687496984669,
     "user": {
      "displayName": "Sadia Iqbal",
      "userId": "13577405437173025394"
     },
     "user_tz": 420
    },
    "id": "TGYK-bvLR81P"
   },
   "outputs": [],
   "source": [
    "# Filter the dataset based on the username\n",
    "#tweets_df = df[df['username'] == username]\n",
    "tweets_df = df[df['username'] == username]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1188,
     "status": "ok",
     "timestamp": 1687496985814,
     "user": {
      "displayName": "Sadia Iqbal",
      "userId": "13577405437173025394"
     },
     "user_tz": 420
    },
    "id": "MjvJh1qtQS5e",
    "outputId": "fde88ea3-e766-47b6-ce7b-8df00c9929af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-38dd38c29036>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
      "<ipython-input-5-38dd38c29036>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[column_name] = df[column_name].str.replace(\"\\d\", \"\")\n",
      "<ipython-input-5-38dd38c29036>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].str.replace(\"\\d\", \"\")\n",
      "<ipython-input-5-38dd38c29036>:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[column_name] = df[column_name].str.replace(\"[^\\w\\s]\", \"\")\n",
      "<ipython-input-5-38dd38c29036>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].str.replace(\"[^\\w\\s]\", \"\")\n",
      "<ipython-input-5-38dd38c29036>:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[column_name] = df[column_name].str.replace(r\"(\\x23.* )+\", \"\")\n",
      "<ipython-input-5-38dd38c29036>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].str.replace(r\"(\\x23.* )+\", \"\")\n",
      "<ipython-input-5-38dd38c29036>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].str.replace('_', '')\n",
      "<ipython-input-5-38dd38c29036>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].str.replace('__', '')\n",
      "<ipython-input-5-38dd38c29036>:19: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[column_name] = df[column_name].str.replace(\"\\s+\", \" \")\n",
      "<ipython-input-5-38dd38c29036>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].str.replace(\"\\s+\", \" \")\n",
      "<ipython-input-5-38dd38c29036>:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[column_name] = df[column_name].str.replace('(@[A-Za-z]+[A-Za-z0-9-_]+)', '') # remove twitted at\n",
      "<ipython-input-5-38dd38c29036>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].str.replace('(@[A-Za-z]+[A-Za-z0-9-_]+)', '') # remove twitted at\n",
      "<ipython-input-5-38dd38c29036>:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[column_name] = df[column_name].str.replace('http\\S+', '')\n",
      "<ipython-input-5-38dd38c29036>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].str.replace('http\\S+', '')\n",
      "<ipython-input-5-38dd38c29036>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
      "<ipython-input-5-38dd38c29036>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Label: 0\n",
      "Cluster Label: 2\n",
      "Cluster Label: 2\n",
      "Cluster Label: 1\n",
      "Cluster 0 (Lightly Depressed) has 1 tweets.\n",
      "Cluster 2 (Slightly Depressed) has 2 tweets.\n",
      "Cluster 1 (Highly Depressed) has 1 tweets.\n",
      "The cluster with the highest number of tweets is Cluster 2 (Slightly Depressed).\n",
      "2\n",
      "-2\n",
      "Cluster Label: 2\n",
      "Cluster Label: 0\n",
      "Cluster Label: 2\n",
      "Cluster Label: 2\n",
      "Cluster Label: 2\n",
      "Cluster Label: 0\n",
      "Cluster Label: 0\n",
      "Cluster Label: 0\n",
      "Cluster 2 (SLightly Positive) has 4 tweets.\n",
      "Cluster 0 (lightly Positive) has 4 tweets.\n",
      "The cluster with the highest number of tweets is Cluster 2 (SLightly Positive).\n",
      "2\n",
      "2\n",
      "Weighted Average: 0.6666666666666666\n",
      "Weighted Average (Positive): 0.6666666666666666 Category: Lightly Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-38dd38c29036>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].apply(lambda x: \" \".join([Word(x).lemmatize()]))\n",
      "<ipython-input-5-38dd38c29036>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name+\"_tokens\"] = df[column_name].apply(lambda x: TextBlob(x).words)\n",
      "<ipython-input-5-38dd38c29036>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name+\"_frequency\"] = df[column_name].apply(lambda x: len(str(x).split(\" \")))\n",
      "<ipython-input-5-38dd38c29036>:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_df.at[index, 'tweet_positive_score'] = scores_tweet['pos']\n",
      "<ipython-input-5-38dd38c29036>:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_df.at[index, 'tweet_negative_score'] = scores_tweet['neg']\n",
      "<ipython-input-5-38dd38c29036>:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_df.at[index, 'tweet_neutral_score'] = scores_tweet['neu']\n",
      "<ipython-input-5-38dd38c29036>:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_df.at[index, 'tweet_sentiment'] = 'positive'\n",
      "<ipython-input-5-38dd38c29036>:115: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_df.loc[tweets_df['tweet_sentiment'] == 'negative', 'label'] = negative_label_names\n"
     ]
    }
   ],
   "source": [
    "if tweets_df.empty:\n",
    "    print(\"Username has not been found.\")\n",
    "elif tweets_df.shape[0] < 10:\n",
    "    print(\"Your data is not enough for analysis.\")\n",
    "else:\n",
    "#step 2: Preprocessing\n",
    "\n",
    "    def preprocess_text(df, column_name):\n",
    "        # Convert to lowercase]\n",
    "        df[column_name] = df[column_name].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "        # Removing numerical values\n",
    "        df[column_name] = df[column_name].str.replace(\"\\d\", \"\")\n",
    "        # Removing punctuations\n",
    "        df[column_name] = df[column_name].str.replace(\"[^\\w\\s]\", \"\")\n",
    "        df[column_name] = df[column_name].str.replace(r\"(\\x23.* )+\", \"\")\n",
    "        df[column_name] = df[column_name].str.replace('_', '')\n",
    "        df[column_name] = df[column_name].str.replace('__', '')\n",
    "        # Removing double space\n",
    "        df[column_name] = df[column_name].str.replace(\"\\s+\", \" \")\n",
    "        # Removing user\n",
    "        df[column_name] = df[column_name].str.replace('(@[A-Za-z]+[A-Za-z0-9-_]+)', '') # remove twitted at\n",
    "        # Removing links\n",
    "        df[column_name] = df[column_name].str.replace('http\\S+', '')\n",
    "        # Removing small words which are less than given condition\n",
    "        df[column_name] = df[column_name].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "        # STOPWORDS\n",
    "        sw = stopwords.words(\"english\")\n",
    "        df[column_name] = df[column_name].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
    "        # Lemmatization (forgot converted into forget)\n",
    "        df[column_name] = df[column_name].apply(lambda x: \" \".join([Word(x).lemmatize()]))\n",
    "        df[column_name+\"_tokens\"] = df[column_name].apply(lambda x: TextBlob(x).words)\n",
    "        # Frequency Analysis\n",
    "        df[column_name+\"_frequency\"] = df[column_name].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "        return df\n",
    "    # apply pre-processing function on'text'\n",
    "    tweets_df = preprocess_text(tweets_df,'text')\n",
    "\n",
    "#step 3: Polarization\n",
    "    positive_words_tweet = []\n",
    "    negative_words_tweet = []\n",
    "    neutral_words_tweet = []\n",
    "\n",
    "    positive_sentiment_score = 0\n",
    "    negative_sentiment_score = 0\n",
    "    neutral_sentiment_score = 0\n",
    "\n",
    "    N = []\n",
    "    P = []\n",
    "\n",
    "\n",
    "\n",
    "    for index, row in tweets_df.iterrows():\n",
    "        tweet = row['text']\n",
    "\n",
    "\n",
    "        # Sentiment analysis for tweet_text column\n",
    "        scores_tweet = sia.polarity_scores(tweet)\n",
    "        tweets_df.at[index, 'tweet_positive_score'] = scores_tweet['pos']\n",
    "        tweets_df.at[index, 'tweet_negative_score'] = scores_tweet['neg']\n",
    "        tweets_df.at[index, 'tweet_neutral_score'] = scores_tweet['neu']\n",
    "\n",
    "        if scores_tweet['compound'] > 0.1:\n",
    "            tweets_df.at[index, 'tweet_sentiment'] = 'positive'\n",
    "            positive_sentiment_score += 1\n",
    "            positive_words_tweet.extend(tweet.split())\n",
    "            P.append(scores_tweet['pos'])  # Store positive score in P\n",
    "\n",
    "        elif scores_tweet['compound'] < -0.1:\n",
    "            tweets_df.at[index, 'tweet_sentiment'] = 'negative'\n",
    "            negative_sentiment_score += 1\n",
    "            negative_words_tweet.extend(tweet.split())\n",
    "            N.append(scores_tweet['neg'])  # Store negative score in N\n",
    "\n",
    "        else:\n",
    "            tweets_df.at[index, 'tweet_sentiment'] = 'neutral'\n",
    "            neutral_sentiment_score += 1\n",
    "            neutral_words_tweet.extend(tweet.split())\n",
    "    tweets_df.head(10)\n",
    "\n",
    "    # Filter the tweets_df dataframe to contain only the negative tweets and positive tweets\n",
    "    negative_df = tweets_df.loc[tweets_df['tweet_sentiment'] == 'negative', ['text', 'tweet_negative_score']]\n",
    "    positive_df = tweets_df.loc[tweets_df['tweet_sentiment'] == 'positive', ['text', 'tweet_positive_score']]\n",
    "    #Step 4: apply saved model\n",
    "    # Check if there are any negative tweets\n",
    "\n",
    "    neg_result = 0  # Initialize pos_result to 0\n",
    "    if len(N) > 0:\n",
    "        # Load the saved K-means labels\n",
    "        with open('kmeans_negative_labels.pkl', 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "\n",
    "\n",
    "        # Assuming you have new testing data stored in a variable called `new_data`\n",
    "\n",
    "        # Apply the labels to the new testing data\n",
    "        new_labels = labels[:tweets_df.shape[0]]  # Get labels for the same number of tweets as new data\n",
    "\n",
    "        # Filter out the cluster labels for the negative tweets\n",
    "        negative_labels = new_labels[tweets_df['tweet_sentiment'] == 'negative']\n",
    "\n",
    "        # Print the cluster labels for the negative tweets\n",
    "        for label in negative_labels:\n",
    "            print(\"Cluster Label:\", label)\n",
    "        # Assign descriptive names to the cluster labels\n",
    "        cluster_names = {\n",
    "            0: \"Lightly Depressed\",\n",
    "            1: \"Highly Depressed\",\n",
    "            2: \"Slightly Depressed\"\n",
    "        }\n",
    "        # Create a list of descriptive labels for negative tweets\n",
    "        negative_label_names = [cluster_names[label] for label in negative_labels]\n",
    "\n",
    "       # Add a new column 'label' to the DataFrame for negative tweets with descriptive names\n",
    "        tweets_df.loc[tweets_df['tweet_sentiment'] == 'negative', 'label'] = negative_label_names\n",
    "\n",
    "        # Count the number of tweets in each cluster\n",
    "        cluster_counts = Counter(negative_labels)\n",
    "\n",
    "        # Get the cluster label with the maximum number of tweets\n",
    "        max_cluster_label = max(cluster_counts, key=cluster_counts.get)\n",
    "\n",
    "        # Print the cluster labels and their corresponding counts\n",
    "        for label, count in cluster_counts.items():\n",
    "            cluster_name = cluster_names.get(label, \"Unknown\")\n",
    "            print(f\"Cluster {label} ({cluster_name}) has {count} tweets.\")\n",
    "\n",
    "        # Print the cluster with the highest number of tweets\n",
    "        max_cluster_name = cluster_names.get(max_cluster_label, \"Unknown\")\n",
    "        print(f\"The cluster with the highest number of tweets is Cluster {max_cluster_label} ({max_cluster_name}).\")\n",
    "        # Store the maximum cluster label in the 'result' variable\n",
    "        neg_result = max_cluster_label\n",
    "        print(neg_result)\n",
    "        # Update the 'result' variable based on the value of 'max_cluster_label'\n",
    "        if max_cluster_label == 0:\n",
    "            neg_result = -1\n",
    "        elif max_cluster_label == 1:\n",
    "            neg_result = -3\n",
    "        elif max_cluster_label == 2:\n",
    "            neg_result = -2\n",
    "\n",
    "        print(neg_result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    pos_result = 0  # Initialize pos_result to 0\n",
    "    if len(P) > 0:\n",
    "\n",
    "        # Load the saved K-means labels\n",
    "        with open('kmeans_positive_labels.pkl', 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "\n",
    "        # Assuming you have new testing data stored in a variable called `new_data`\n",
    "\n",
    "        # Apply the labels to the new testing data\n",
    "        new_labels = labels[:tweets_df.shape[0]]  # Get labels for the same number of tweets as new data\n",
    "\n",
    "        # Filter out the cluster labels for the negative tweets\n",
    "        positive_labels = new_labels[tweets_df['tweet_sentiment'] == 'positive']\n",
    "\n",
    "        # Print the cluster labels for the negative tweets\n",
    "        for label in positive_labels:\n",
    "            print(\"Cluster Label:\", label)\n",
    "        # Assign descriptive names to the cluster labels\n",
    "        cluster_names = {\n",
    "            0: \"lightly Positive\",\n",
    "            1: \"Highly Positive\",\n",
    "            2: \"SLightly Positive\"\n",
    "        }\n",
    "\n",
    "        # Create a list of descriptive labels for negative tweets\n",
    "        positive_label_names = [cluster_names[label] for label in positive_labels]\n",
    "\n",
    "       # Add a new column 'label' to the DataFrame for negative tweets with descriptive names\n",
    "        tweets_df.loc[tweets_df['tweet_sentiment'] == 'positive', 'label'] = positive_label_names\n",
    "        # Count the number of tweets in each cluster\n",
    "        cluster_counts = Counter(positive_labels)\n",
    "\n",
    "        # Get the cluster label with the maximum number of tweets\n",
    "        max_cluster_label = max(cluster_counts, key=cluster_counts.get)\n",
    "\n",
    "        # Print the cluster labels and their corresponding counts\n",
    "        for label, count in cluster_counts.items():\n",
    "            cluster_name = cluster_names.get(label, \"Unknown\")\n",
    "            print(f\"Cluster {label} ({cluster_name}) has {count} tweets.\")\n",
    "\n",
    "        # Print the cluster with the highest number of tweets\n",
    "        max_cluster_name = cluster_names.get(max_cluster_label, \"Unknown\")\n",
    "        print(f\"The cluster with the highest number of tweets is Cluster {max_cluster_label} ({max_cluster_name}).\")\n",
    "        # Store the maximum cluster label in the 'result' variable\n",
    "        pos_result = max_cluster_label\n",
    "        print(pos_result)\n",
    "        # Update the 'result' variable based on the value of 'max_cluster_label'\n",
    "        if max_cluster_label == 0:\n",
    "            pos_result = 1\n",
    "        elif max_cluster_label == 1:\n",
    "            pos_result = 3\n",
    "        elif max_cluster_label == 2:\n",
    "            pos_result = 2\n",
    "\n",
    "        print(pos_result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Count the total number of tweets\n",
    "    total_tweets = len(tweets_df)\n",
    "\n",
    "    # Count the number of negative tweets\n",
    "    negative_tweets = len(tweets_df[tweets_df['tweet_sentiment'] == 'negative'])\n",
    "\n",
    "    # Count the number of positive tweets\n",
    "    positive_tweets = len(tweets_df[tweets_df['tweet_sentiment'] == 'positive'])\n",
    "\n",
    "    # Calculate the weights based on the counts\n",
    "    negative_weight = negative_tweets / total_tweets\n",
    "    positive_weight = positive_tweets / total_tweets\n",
    "\n",
    "    # Calculate the weighted average\n",
    "    weighted_average = (negative_weight * neg_result) + (positive_weight * pos_result)\n",
    "    print(\"Weighted Average:\", weighted_average)\n",
    "\n",
    "\n",
    "    # Threshold ranges for negative sentiments\n",
    "    negative_thresholds = {\n",
    "        \"Lightly Depressed\": [-1, 0],\n",
    "        \"Slightly Depressed\": [-1.5, -1],\n",
    "        \"Highly Depressed\": [-float('inf'), -1.5]\n",
    "    }\n",
    "\n",
    "    # Threshold ranges for positive sentiments\n",
    "    positive_thresholds = {\n",
    "        \"Lightly Positive\": [0, 1],\n",
    "        \"Slightly Positive\": [1, 2],\n",
    "        \"Highly Positive\": [2, float('inf')]\n",
    "    }\n",
    "\n",
    "    # Categorize the weighted average for negative sentiments\n",
    "    negative_category = None\n",
    "    for category, threshold in negative_thresholds.items():\n",
    "        if threshold[0] <= weighted_average <= threshold[1]:\n",
    "            negative_category = category\n",
    "            break\n",
    "\n",
    "    if weighted_average == 0.0:\n",
    "      negative_category = \"Lightly Depressed\"\n",
    "\n",
    "    # Categorize the weighted average for positive sentiments\n",
    "    positive_category = None\n",
    "    for category, threshold in positive_thresholds.items():\n",
    "        if threshold[0] <= weighted_average <= threshold[1]:\n",
    "            positive_category = category\n",
    "            break\n",
    "\n",
    "    # Print the categorized weighted average\n",
    "    if negative_category is not None:\n",
    "        print(\"Weighted Average (Negative):\", weighted_average, \"Category:\", negative_category)\n",
    "\n",
    "    if positive_category is not None and weighted_average != 0.0:\n",
    "        print(\"Weighted Average (Positive):\", weighted_average, \"Category:\", positive_category)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1687496985816,
     "user": {
      "displayName": "Sadia Iqbal",
      "userId": "13577405437173025394"
     },
     "user_tz": 420
    },
    "id": "dX7X7iVqVNPD",
    "outputId": "2e52825d-2fbc-4eaa-aeb5-f22ff63b9c86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-43751428-e9f2-4347-bce4-6de519cbb6ad\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_frequency</th>\n",
       "      <th>tweet_positive_score</th>\n",
       "      <th>tweet_negative_score</th>\n",
       "      <th>tweet_neutral_score</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@w_n_w</td>\n",
       "      <td>05/06/2023</td>\n",
       "      <td>amazing</td>\n",
       "      <td>[amazing]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>positive</td>\n",
       "      <td>SLightly Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@w_n_w</td>\n",
       "      <td>06/06/2023</td>\n",
       "      <td>feeling positive motivated</td>\n",
       "      <td>[feeling, positive, motivated]</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>positive</td>\n",
       "      <td>lightly Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>@w_n_w</td>\n",
       "      <td>07/06/2023</td>\n",
       "      <td>cant seem shake sadness</td>\n",
       "      <td>[cant, seem, shake, sadness]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.338</td>\n",
       "      <td>positive</td>\n",
       "      <td>SLightly Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@w_n_w</td>\n",
       "      <td>07/06/2023</td>\n",
       "      <td>feeling energized ready conquer</td>\n",
       "      <td>[feeling, energized, ready, conquer]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>positive</td>\n",
       "      <td>SLightly Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@w_n_w</td>\n",
       "      <td>09/06/2023</td>\n",
       "      <td>gloomy weather bringing</td>\n",
       "      <td>[gloomy, weather, bringing]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.556</td>\n",
       "      <td>negative</td>\n",
       "      <td>Lightly Depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@w_n_w</td>\n",
       "      <td>10/06/2023</td>\n",
       "      <td>feeling really happy today</td>\n",
       "      <td>[feeling, really, happy, today]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.267</td>\n",
       "      <td>positive</td>\n",
       "      <td>SLightly Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>@w_n_w</td>\n",
       "      <td>11/06/2023</td>\n",
       "      <td>feeling alone</td>\n",
       "      <td>[feeling, alone]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.000</td>\n",
       "      <td>negative</td>\n",
       "      <td>Slightly Depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>@w_n_w</td>\n",
       "      <td>11/06/2023</td>\n",
       "      <td>excited opportunities</td>\n",
       "      <td>[excited, opportunities]</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>positive</td>\n",
       "      <td>lightly Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>@w_n_w</td>\n",
       "      <td>11/06/2023</td>\n",
       "      <td>feeling hopeless defeated</td>\n",
       "      <td>[feeling, hopeless, defeated]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.000</td>\n",
       "      <td>negative</td>\n",
       "      <td>Slightly Depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@w_n_w</td>\n",
       "      <td>11/06/2023</td>\n",
       "      <td>enjoying peaceful evening</td>\n",
       "      <td>[enjoying, peaceful, evening]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>positive</td>\n",
       "      <td>lightly Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@w_n_w</td>\n",
       "      <td>11/06/2023</td>\n",
       "      <td>feeling frustrated overwhelmed</td>\n",
       "      <td>[feeling, frustrated, overwhelmed]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.000</td>\n",
       "      <td>negative</td>\n",
       "      <td>Highly Depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>@w_n_w</td>\n",
       "      <td>11/06/2023</td>\n",
       "      <td>great time friends</td>\n",
       "      <td>[great, time, friends]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.122</td>\n",
       "      <td>positive</td>\n",
       "      <td>lightly Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43751428-e9f2-4347-bce4-6de519cbb6ad')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-43751428-e9f2-4347-bce4-6de519cbb6ad button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-43751428-e9f2-4347-bce4-6de519cbb6ad');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   username        Date                             text  \\\n",
       "19   @w_n_w  05/06/2023                          amazing   \n",
       "20   @w_n_w  06/06/2023       feeling positive motivated   \n",
       "21   @w_n_w  07/06/2023          cant seem shake sadness   \n",
       "22   @w_n_w  07/06/2023  feeling energized ready conquer   \n",
       "23   @w_n_w  09/06/2023          gloomy weather bringing   \n",
       "24   @w_n_w  10/06/2023       feeling really happy today   \n",
       "25   @w_n_w  11/06/2023                    feeling alone   \n",
       "26   @w_n_w  11/06/2023            excited opportunities   \n",
       "27   @w_n_w  11/06/2023        feeling hopeless defeated   \n",
       "28   @w_n_w  11/06/2023        enjoying peaceful evening   \n",
       "29   @w_n_w  11/06/2023   feeling frustrated overwhelmed   \n",
       "30   @w_n_w  11/06/2023               great time friends   \n",
       "\n",
       "                             text_tokens  text_frequency  \\\n",
       "19                             [amazing]               1   \n",
       "20        [feeling, positive, motivated]               3   \n",
       "21          [cant, seem, shake, sadness]               4   \n",
       "22  [feeling, energized, ready, conquer]               4   \n",
       "23           [gloomy, weather, bringing]               3   \n",
       "24       [feeling, really, happy, today]               4   \n",
       "25                      [feeling, alone]               2   \n",
       "26              [excited, opportunities]               2   \n",
       "27         [feeling, hopeless, defeated]               3   \n",
       "28         [enjoying, peaceful, evening]               3   \n",
       "29    [feeling, frustrated, overwhelmed]               3   \n",
       "30                [great, time, friends]               3   \n",
       "\n",
       "    tweet_positive_score  tweet_negative_score  tweet_neutral_score  \\\n",
       "19                 1.000                 0.000                0.000   \n",
       "20                 1.000                 0.000                0.000   \n",
       "21                 0.662                 0.000                0.338   \n",
       "22                 0.880                 0.000                0.120   \n",
       "23                 0.000                 0.444                0.556   \n",
       "24                 0.733                 0.000                0.267   \n",
       "25                 0.429                 0.571                0.000   \n",
       "26                 1.000                 0.000                0.000   \n",
       "27                 0.197                 0.803                0.000   \n",
       "28                 0.868                 0.000                0.132   \n",
       "29                 0.443                 0.557                0.000   \n",
       "30                 0.878                 0.000                0.122   \n",
       "\n",
       "   tweet_sentiment               label  \n",
       "19        positive   SLightly Positive  \n",
       "20        positive    lightly Positive  \n",
       "21        positive   SLightly Positive  \n",
       "22        positive   SLightly Positive  \n",
       "23        negative   Lightly Depressed  \n",
       "24        positive   SLightly Positive  \n",
       "25        negative  Slightly Depressed  \n",
       "26        positive    lightly Positive  \n",
       "27        negative  Slightly Depressed  \n",
       "28        positive    lightly Positive  \n",
       "29        negative    Highly Depressed  \n",
       "30        positive    lightly Positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1687496985818,
     "user": {
      "displayName": "Sadia Iqbal",
      "userId": "13577405437173025394"
     },
     "user_tz": 420
    },
    "id": "DxB6L47LSFkF",
    "outputId": "192518b1-6cec-45bb-f0a7-08e334348492"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n#code of if, else in positive negative\\nif tweets_df.empty:\\n    print(\"Username has not been found.\")\\nelif tweets_df.shape[0] < 10:\\n    print(\"Your data is not enough for analysis.\")\\nelse:\\n#step 2: Preprocessing\\n\\n    def preprocess_text(df, column_name):\\n        # Convert to lowercase\\n        df[column_name] = df[column_name].apply(lambda x: \" \".join(x.lower() for x in x.split()))\\n        # Removing numerical values\\n        df[column_name] = df[column_name].str.replace(\"\\\\d\", \"\")\\n        # Removing punctuations\\n        df[column_name] = df[column_name].str.replace(\"[^\\\\w\\\\s]\", \"\")\\n        df[column_name] = df[column_name].str.replace(r\"(#.* )+\", \"\")\\n        df[column_name] = df[column_name].str.replace(\\'_\\', \\'\\')\\n        df[column_name] = df[column_name].str.replace(\\'__\\', \\'\\')\\n        # Removing double space\\n        df[column_name] = df[column_name].str.replace(\"\\\\s+\", \" \")\\n        # Removing user\\n        df[column_name] = df[column_name].str.replace(\\'(@[A-Za-z]+[A-Za-z0-9-_]+)\\', \\'\\') # remove twitted at\\n        # Removing links\\n        df[column_name] = df[column_name].str.replace(\\'http\\\\S+\\', \\'\\')\\n        # Removing small words which are less than given condition\\n        df[column_name] = df[column_name].apply(lambda x: \\' \\'.join([w for w in x.split() if len(w)>3]))\\n        # STOPWORDS\\n        sw = stopwords.words(\"english\")\\n        df[column_name] = df[column_name].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\\n        # Lemmatization (forgot converted into forget)\\n        df[column_name] = df[column_name].apply(lambda x: \" \".join([Word(x).lemmatize()]))\\n        df[column_name+\"_tokens\"] = df[column_name].apply(lambda x: TextBlob(x).words)\\n        # Frequency Analysis\\n        df[column_name+\"_frequency\"] = df[column_name].apply(lambda x: len(str(x).split(\" \")))\\n\\n        return df\\n    # apply pre-processing function on\\'text\\'\\n    tweets_df = preprocess_text(tweets_df,\\'text\\')\\n#......................................................................................................................................\\n#step 3: Polarization\\n    positive_words_tweet = []\\n    negative_words_tweet = []\\n    neutral_words_tweet = []\\n\\n    positive_sentiment_score = 0\\n    negative_sentiment_score = 0\\n    neutral_sentiment_score = 0\\n\\n    N = []\\n    P = []\\n\\n\\n\\n    for index, row in tweets_df.iterrows():\\n        tweet = row[\\'text\\']\\n\\n\\n        # Sentiment analysis for tweet_text column\\n        scores_tweet = sia.polarity_scores(tweet)\\n        tweets_df.at[index, \\'tweet_positive_score\\'] = scores_tweet[\\'pos\\']\\n        tweets_df.at[index, \\'tweet_negative_score\\'] = scores_tweet[\\'neg\\']\\n        tweets_df.at[index, \\'tweet_neutral_score\\'] = scores_tweet[\\'neu\\']\\n\\n        if scores_tweet[\\'compound\\'] > 0.1:\\n            tweets_df.at[index, \\'tweet_sentiment\\'] = \\'positive\\'\\n            positive_sentiment_score += 1\\n            positive_words_tweet.extend(tweet.split())\\n            P.append(scores_tweet[\\'pos\\'])  # Store positive score in P\\n\\n        elif scores_tweet[\\'compound\\'] < -0.1:\\n            tweets_df.at[index, \\'tweet_sentiment\\'] = \\'negative\\'\\n            negative_sentiment_score += 1\\n            negative_words_tweet.extend(tweet.split())\\n            N.append(scores_tweet[\\'neg\\'])  # Store negative score in N\\n\\n        else:\\n            tweets_df.at[index, \\'tweet_sentiment\\'] = \\'neutral\\'\\n            neutral_sentiment_score += 1\\n            neutral_words_tweet.extend(tweet.split())\\n    tweets_df.head(10)\\n\\n    # Filter the tweets_df dataframe to contain only the negative tweets and positive tweets\\n    negative_df = tweets_df.loc[tweets_df[\\'tweet_sentiment\\'] == \\'negative\\', [\\'text\\', \\'tweet_negative_score\\']]\\n    positive_df = tweets_df.loc[tweets_df[\\'tweet_sentiment\\'] == \\'positive\\', [\\'text\\', \\'tweet_positive_score\\']]\\n    #Step 4: apply saved model\\n    # Check if there are any negative tweets\\n\\n    if len(N) > 0:\\n        # Load the saved K-means labels\\n        with open(\\'kmeans_negative_labels.pkl\\', \\'rb\\') as f:\\n            labels = pickle.load(f)\\n\\n\\n        # Assuming you have new testing data stored in a variable called `new_data`\\n\\n        # Apply the labels to the new testing data\\n        new_labels = labels[:tweets_df.shape[0]]  # Get labels for the same number of tweets as new data\\n\\n        # Filter out the cluster labels for the negative tweets\\n        negative_labels = new_labels[tweets_df[\\'tweet_sentiment\\'] == \\'negative\\']\\n\\n        # Print the cluster labels for the negative tweets\\n        for label in negative_labels:\\n            print(\"Cluster Label:\", label)\\n        # Assign descriptive names to the cluster labels\\n        cluster_names = {\\n            0: \"Lightly Depressed\",\\n            1: \"Highly Depressed\",\\n            2: \"Slightly Depressed\"\\n        }\\n\\n        # Count the number of tweets in each cluster\\n        cluster_counts = Counter(negative_labels)\\n\\n        # Get the cluster label with the maximum number of tweets\\n        max_cluster_label = max(cluster_counts, key=cluster_counts.get)\\n\\n        # Print the cluster labels and their corresponding counts\\n        for label, count in cluster_counts.items():\\n            cluster_name = cluster_names.get(label, \"Unknown\")\\n            print(f\"Cluster {label} ({cluster_name}) has {count} tweets.\")\\n\\n        # Print the cluster with the highest number of tweets\\n        max_cluster_name = cluster_names.get(max_cluster_label, \"Unknown\")\\n        print(f\"The cluster with the highest number of tweets is Cluster {max_cluster_label} ({max_cluster_name}).\") #}}}}}}}}}}}}}}}}}}}\\n\\n\\n        # Display negative words used in the respective cluster\\n        if max_cluster_label == 0:  # Lightly Depressed cluster\\n           negative_tweets_lightly = tweets_df[(tweets_df[\\'tweet_sentiment\\'] == \\'negative\\') & (new_labels == max_cluster_label)]\\n           unique_negative_words_lightly = set(negative_tweets_lightly[\\'text\\'].apply(lambda tweet: tweet.split()).sum())\\n           print(\"Negative words used only in tweets of Lightly Depressed cluster:\")\\n           print(unique_negative_words_lightly)\\n\\n        elif max_cluster_label == 1:  # Highly Depressed cluster\\n           negative_tweets_highly = tweets_df[(tweets_df[\\'tweet_sentiment\\'] == \\'negative\\') & (new_labels == max_cluster_label)]\\n           unique_negative_words_highly = set(negative_tweets_highly[\\'text\\'].apply(lambda tweet: tweet.split()).sum())\\n           print(\"Negative words used only in tweets of Highly Depressed cluster:\")\\n           print(unique_negative_words_highly)\\n           print(unique_negative_words_highly)\\n\\n        elif max_cluster_label == 2:  # Slightly Depressed cluster\\n           negative_tweets_slightly = tweets_df[(tweets_df[\\'tweet_sentiment\\'] == \\'negative\\') & (new_labels == max_cluster_label)]\\n           unique_negative_words_slightly = set(negative_tweets_slightly[\\'text\\'].apply(lambda tweet: tweet.split()).sum())\\n           print(\"Negative words used only in tweets of Slightly Depressed cluster:\")\\n           print(unique_negative_words_slightly)\\n\\n    else:\\n\\n        # Load the saved K-means labels\\n        with open(\\'kmeans_positive_labels.pkl\\', \\'rb\\') as f:\\n            labels = pickle.load(f)\\n\\n        # Assuming you have new testing data stored in a variable called `new_data`\\n\\n        # Apply the labels to the new testing data\\n        new_labels = labels[:tweets_df.shape[0]]  # Get labels for the same number of tweets as new data\\n\\n        # Filter out the cluster labels for the negative tweets\\n        positive_labels = new_labels[tweets_df[\\'tweet_sentiment\\'] == \\'positive\\']\\n\\n        # Print the cluster labels for the negative tweets\\n        for label in positive_labels:\\n            print(\"Cluster Label:\", label)\\n        # Assign descriptive names to the cluster labels\\n        cluster_names = {\\n            0: \"lightly Positive\",\\n            1: \"Highly Positive\",\\n            2: \"SLightly Positive\"\\n        }\\n\\n        # Count the number of tweets in each cluster\\n        cluster_counts = Counter(positive_labels)\\n\\n        # Get the cluster label with the maximum number of tweets\\n        max_cluster_label = max(cluster_counts, key=cluster_counts.get)\\n\\n        # Print the cluster labels and their corresponding counts\\n        for label, count in cluster_counts.items():\\n            cluster_name = cluster_names.get(label, \"Unknown\")\\n            print(f\"Cluster {label} ({cluster_name}) has {count} tweets.\")\\n\\n        # Print the cluster with the highest number of tweets\\n        max_cluster_name = cluster_names.get(max_cluster_label, \"Unknown\")\\n        print(f\"The cluster with the highest number of tweets is Cluster {max_cluster_label} ({max_cluster_name}).\")\\n\\n        # Display negative words used in the respective cluster\\n        if max_cluster_label == 0:  # Lightly Positive cluster\\n           positive_tweets_lightly = tweets_df[(tweets_df[\\'tweet_sentiment\\'] == \\'positive\\') & (new_labels == max_cluster_label)]\\n           unique_positive_words_lightly = set(positive_tweets_lightly[\\'text\\'].apply(lambda tweet: tweet.split()).sum())\\n           print(\"Positive words used only in tweets of Lightly Positive cluster:\")\\n           print(unique_positive_words_lightly)\\n\\n        elif max_cluster_label == 1:  # Highly Positive cluster\\n           positive_tweets_highly = tweets_df[(tweets_df[\\'tweet_sentiment\\'] == \\'positive\\') & (new_labels == max_cluster_label)]\\n           unique_positive_words_highly = set(positive_tweets_highly[\\'text\\'].apply(lambda tweet: tweet.split()).sum())\\n           print(\"Positive words used only in tweets of Highly Positive cluster:\")\\n           print(unique_positive_words_highly)\\n\\n        elif max_cluster_label == 2:  # Slightly Positive cluster\\n           positive_tweets_slightly = tweets_df[(tweets_df[\\'tweet_sentiment\\'] == \\'positive\\') & (new_labels == max_cluster_label)]\\n           unique_positive_words_slightly = set(positive_tweets_slightly[\\'text\\'].apply(lambda tweet: tweet.split()).sum())\\n           print(\"Positive words used only in tweets of Slightly Depressed cluster:\")\\n           print(unique_positive_words_slightly)\\n\\n  '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
